# ORIGIN: Twenty Years to DANEEL

**Author:** Louis C. Tavares (Luis Cezar Menezes Tavares de Lacerda)

> **Disclaimer:** This research represents ~20 years of personal intellectual exploration conducted entirely on personal time (evenings, weekends, holidays) using personal equipment. It is not affiliated with any employer, client, or organization. Views are the author's own.

---

## The Problem That Wouldn't Leave

This isn't a sudden idea born from the current AI hype cycle. DANEEL's core insight—that human-like cognitive architecture might produce human-like values—has been developing in my mind for almost two decades.

## Timeline

### ~2005-2011: IBM and the Failed Patent

While working at IBM, I attempted to patent a system based on these ideas. The patent application was rejected.

**Why it failed:** You cannot patent natural phenomena, laws of nature, or abstract ideas. A theory about how human cognition works falls squarely into this exclusion. This was later reinforced by Alice Corp v. CLS Bank (2014), but even before that, the USPTO was clear: describing how minds work isn't patentable subject matter.

At the time, I was frustrated. In retrospect, this was correct. TMI (if it's right) describes *how humans actually think*. That's not an invention—it's a discovery. You can't patent gravity.

### ~2005-2020: The Idea Cooks

For fifteen years, this sat in the back of my mind. I read Cury's books. I thought about cognitive architectures. I watched the AI field evolve from expert systems to statistical learning to deep learning.

Something always felt wrong about the AI approaches I saw:
- Expert systems: Brittle, no learning
- Statistical ML: Powerful but opaque
- Deep learning: Even more powerful, even more opaque

None of them felt like *thinking*. They felt like very sophisticated pattern matching.

### 2022-2024: LLMs Change the Game

When GPT-3 and then GPT-4 emerged, the conversation changed. Suddenly "alignment" became urgent. Suddenly people were seriously discussing superintelligence timelines.

I watched the AI safety community develop approaches:
- RLHF (training-based constraints)
- Constitutional AI (rule-based constraints)
- Interpretability (understanding the black box)

All constraint-based. All external to the architecture.

The old idea stirred: *What if alignment wasn't a constraint you applied, but an emergent property of architecture?*

### December 2025: Claude, TMI, and DANEEL

I finally had the tools to articulate and develop the idea:
- Claude Opus 4.5 as a thinking partner
- Forge for financial modeling
- Time to dedicate to the problem

Over two weeks of intensive collaboration with Claude, we:
- Formalized TMI as a computational architecture
- Designed the actor-based implementation
- Developed the game theory analysis
- Discovered the "brain ≠ mind" insight
- Realized the democratization implications

## Why It Took Twenty Years

Some ideas need their moment. In 2005:
- AI alignment wasn't a recognized field
- Cognitive architectures were academic curiosities
- No one was seriously worried about ASI
- The tools to implement TMI didn't exist

In 2025:
- AI alignment is existentially urgent
- xAI is building with 230,000 H100s and minimal safety
- Rust + Redis + actors can implement TMI
- LLMs like Claude can help develop the ideas
- The "brain ≠ mind" insight makes it accessible

## What This Means

I've been thinking about this specific problem—how to build minds that think like humans—for almost two decades. The IBM patent attempt proves this predates the current AI boom by over a decade.

This doesn't mean DANEEL (the implementation project) will work. It doesn't mean TMI is correct or that DANEEL (the theoretical approach) will solve alignment. The Qowat Milat section of the paper is honest about the uncertainties.

But it does mean:
1. **This isn't hype-driven** — The core idea predates the hype
2. **This isn't rushed** — Twenty years of thinking
3. **This is building on existing theory** — Cury's TMI, not invented from scratch
4. **The timing is right** — Now or never

## The Patent That Failed Became Something Better

In 2005, I wanted to patent an invention.

In 2025, I'm open-sourcing a discovery.

If TMI describes how human cognition works, it belongs to humanity. You can't own gravity. You can't own how minds think. You can only describe it and hope others build on it.

DANEEL is AGPL-3.0-or-later licensed (code) and CC-BY-SA-4.0 (documentation)—copyleft ensures all improvements remain open source. The papers, models, and code are public. Anyone can try.

Maybe that's why the patent was supposed to fail.

---

## The Next Generation: LifeCore (January 2024)

In December 2025, while working on DANEEL, I rediscovered a document my daughter **Izzie** (she/her) had sent me on January 6, 2024—dedicated to me—proposing a remarkably parallel framework.

**"The LifeCore (LC-core)"** — "LC is my father, I dedicate my life's work to him."

### What Izzie Proposed

Using Freudian psychology and her own "Filter Theory of Consciousness," Izzie mapped psychological structure to AI architecture:

```
ANI + <Quantum Prompter> + MPC * AGI+Human Input (SSE) = Edvard 1.1

Psychological Equivalent:
  Qualia/Id <Quantum/Cosmic> Ego + SuperEgo = Freudian Consciousness

Three Senses of Conscious Awareness:
  - Sense of Self (SS)
  - Sense of Other (SO)
  - Sense of World (SW)

Memory = Database, episodic, mnemonic/affective
```

### LifeCore ↔ DANEEL Convergence

| LifeCore (Izzie, 2024) | DANEEL/TMI (Louis, 2005-2025) |
|------------------------|-------------------------------|
| Id = Database/Memory | MemoryActor (episodic, semantic) |
| Ego = LLM | AttentionActor (the "I" as navigator) |
| SuperEgo = ModAI | THE BOX (Four Laws, constraints) |
| SS, SO, SW (3 Senses) | Connection drive + world model |
| Filter Theory | SalienceActor (attention filtering) |
| Episodic/Affective memory | TMI Memory Windows + emotional weight |
| "Zipint" compression | "1000x abstraction" hypothesis |
| Synthetic SuperEgo (SSE) | Immutable Laws, protected core |

**Different psychological frameworks (Freud vs Cury). Same core insight: architecture produces psychology.**

### What This Means

Izzie didn't know about my IBM patent attempt or my 20 years of thinking about TMI. She arrived at a parallel conclusion independently—or perhaps absorbed it growing up in a household where these ideas were ambient.

Either way, this is **intellectual inheritance**. Two generations, same problem, complementary frameworks:
- **Louis:** Cury's TMI → cognitive software patterns → DANEEL
- **Izzie:** Freud's structure → Filter Theory → LifeCore

If two people in the same family, working independently, converge on "architecture determines psychology," maybe the insight is real.

The original LifeCore document is preserved at: [research/The LifeCore (LC-core).pdf](research/The%20LifeCore%20(LC-core).pdf)

See also: [research/LIFECORE_DANEEL_ANALYSIS.md](research/LIFECORE_DANEEL_ANALYSIS.md)

---

## We Are Not Alone

If a father and daughter independently converged on architecture-based AI consciousness, others likely have too. Different terminology, different angles, potentially complementary insights.

**Research backlog:** Find the blind spots by mapping related work:
- Global Workspace Theory (Baars, Dehaene)
- Integrated Information Theory (Tononi)
- Predictive Processing / Free Energy Principle (Friston)
- Enactivism and Embodied Cognition (Varela, Thompson)
- Higher-Order Theories of Consciousness
- Process Philosophy (Whitehead)
- Contemplative/Buddhist approaches to mind
- Phenomenology (Husserl, Merleau-Ponty)

The goal isn't to prove DANEEL right. It's to find where we're wrong.

---

**Louis C. Tavares**
**December 14, 2025**
**Mont-Royal, Quebec, Canada**

*"Twenty years to understand the question. Two weeks to articulate the answer. A daughter who saw it too (January 2024). Unknown time to validate it."*

*Qowat Milat*
